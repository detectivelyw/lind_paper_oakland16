\section{Introduction}
\label{sec.introduction}

To run applications on a computer, it is critical to manage the underlying hardware resources, 
such as a CPU, file systems, and network, and provide an interface to execute requests. 
In modern computer systems, either a hypervisor or an operating system (OS) 
performs this important function. Unfortunately, executing this function 
can be a risky proposition. Privileged code within an operating system kernel 
may contain flaws and vulnerabilities. If the kernel is successfully attacked by 
malicious parties, these flaws can open unrestricted access to the system. 
One critical flaw, discovered in the Linux kernel in the futex subsystem call can 
allow an attacker to gain ring 0 control via the futex syscall, and potentially 
execute arbitrary code with kernel mode privileges \cite{CVE-2014-3153}.

Given the threat such a flaw poses, particularly if the intruder employs 
privilege escalation to increase his level of control over the system, 
it is clear that decreasing the feasibility of an attack on privileged code 
would be a substantial step toward stronger security for computer systems. 
An awareness of this problem has motivated development of a diverse 
set of defensive technologies, including OS virtualization, system call filtering, 
and library OSes. However, these systems have limitations. First, they increase 
the amount of privileged code in the system and introduce new code that 
may harbor exploitable vulnerabilities. For example, a vulnerability in VMware 
caused by buffer overflows in the VIX API could allow local users to execute 
arbitrary code in the host OS \cite{CVE-2008-2100}. Second, even with these technologies in place, 
applications from the user space could still have access to a portion of the kernel 
that contains bugs and thus pose a risk if triggered. KVM \cite{KVM-Attack} and 
VMWare Workstation \cite{VMWare-Attack} have experienced direct attacks on the underlying 
host OS that allowed the attacker to escape out of a guest VM.

In this paper, we introduce a new strategy for addressing the very real risk posed by 
contact between privileged code in an OS kernel and potentially flaw-triggering applications. 
We begin by developing a metric that helps identify where within the kernel these vulnerabilities 
are likely to be located. Our key hypothesis on which the metric is based is that 
commonly-used kernel paths contain fewer bugs, and therefore, can be exposed with minimal risk. 
After running tests by obtaining the kernel trace data to identify which lines of code are executed 
when invoking system calls through popular user applications, we used our new metric for 
kernel coverage safety to create a design paradigm for virtualization systems. 
To prevent the kernel vulnerabilities from being exploited, we ``safely-reimplemented'' system calls 
to provide a POSIX interface to applications. The safe-reimplementation of POSIX attempts to 
minimize the use of risky privileged code by calling only safe parts of the kernel.

Lastly, we used the design paradigm to develop and test a new sandbox system Lind, 
which further minimizes the amount of risky privileged code exposed to untrusted programs 
by reimplementation. This reimplementation is done by our own restricted set of Python code 
inside a sandbox with a very small trusted computing base (TCB), comprised of only about 
8K lines of code (LOC). The additional level of sandboxing is designed to provide an outlet 
for risky functionality needed to run legacy programs,  while containing the security flaws in the code itself. 

The performance of Lind was evaluated in a two-step process. 
First, we captured kernel traces from user programs run in Lind and four other virtualization systems, 
and compared their kernel traces. Second, we examined historical kernel bug reports to 
verify which trace was more likely to trigger bugs. Results showed that applications run in 
Lind are the least likely to trigger kernel bugs. Our implementation of Lind 
only triggered one (2.9\%) of the kernel vulnerabilities we examined, 
while virtualization systems built without our metric triggered significantly (10x) more vulnerabilities. 
This suggests that our metric can help effectively design and build securer virtualization systems.

The main contributions of this paper are as follows:

\begin{itemize}
\item We proposed a novel metric for quantitatively measuring and evaluating 
the security of privileged code, such as in an OS kernel. Our metric examined the safety of the kernel trace, 
at the lines-of-code level, generated by running user applications and producing design recommendations.

\item Using our metric, we have substantiated our key hypothesis that 
commonly used kernel paths contain fewer bugs. 

\item We created a novel secure ``safely-reimplement'' design by examining and leveraging our metric 
and key hypothesis that commonly used kernel paths contain fewer bugs. 
Our design reimplements risky system calls inside a sandbox that only uses safe kernel paths. 

\item With this new design, we implemented a sandbox security system, Lind, 
that provides a secure environment for applications and strong protection for the kernel.

\item Results showed that the implementation of Lind only triggered one (2.9\%) 
of the kernel vulnerabilities we examined, while systems built without using 
our metric triggered significantly (10x) more vulnerabilities. 
This suggests that our metric can help design and build virtualization systems with greater security. 
\end{itemize}

The remainder of this paper is organized as follows. 
We discuss the motivation that drove our work and key background information in \S{\ref{sec.motivation-and-background}}. 
In \S{\ref{sec.metric}}, we propose our kernel coverage safety metric to solve the existing security problems. 
A new system design using this metric is introduced in \S{\ref{sec.design}}. In \S{\ref{sec.implementation}}, 
we describe the implementation of our design, 
the sandbox security system Lind. Evaluation results of Lind compared to 
other existing virtualization systems are presented in \S{\ref{sec.evaluation}}. Limitations and future work are discussed in \S{\ref{sec.limitation}}. 
We then discuss related work in \S{\ref{sec.related_work}} and conclude in \S{\ref{sec.conclusion}}.