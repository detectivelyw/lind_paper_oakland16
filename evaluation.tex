\section{Evaluation}
\label{sec.evaluation}

In seeking to evaluate the performance of Lind, 
we designed and conducted a set of experiments based around four
fundamental 
questions:

\begin{itemize}
\item What are the benefits of running applications in Lind, 
and not in other existing virtualization systems?
(\S{\ref{Linux-Kernel-Bug-Test-and-Evaluation}})

\item Why is Lind less likely to trigger kernel bugs compared to 
other virtualization systems?
(\S{\ref{Reachable-Kernel-Trace-Analysis-for-Different-Virtualization-Systems}})

\item Is Lind really secure? What happens if one of the building blocks
of Lind, 
the Repy sandbox kernel has bugs?
(\S{\ref{Reachable-Kernel-Trace-Analysis-for-Repy-Sandbox}})

\item Is Lind a practical tool that can run real-world applications at
reasonable overhead? 
(\S{\ref{Performance-Evaluation}})
\end{itemize}

In this section, we describe the experiments designed to answer these
question, 
and discuss how the results support the merits of our secure design and its
prototype Lind. 

\subsection{Evaluation Methodology}

Our evaluation strategy was to directly compare the performance of Lind
against 
four other existing virtualization systems\textendash VirtualBox, VMWare
Workstation, 
Docker, and Graphene. We also compared it against Native Linux and used 
those results as a baseline for evaluation. Because Native Linux is the
original OS, 
without virtualization and additional protection, this data helps to
clarify the security benefits of Lind, 
as well as whatever performance overhead costs the system may incur.

\textbf{Experimental setup.}
We conducted our experiments under Linux kernel 3.14.1, using the following
protocols:

\begin{itemize}
\item We identified and examined a list of  69 historical bugs that have
specifically 
targeted Linux kernel 3.14.1 \cite{CVE-Datasource}. Through analyzing
security kernel patches for those bugs, 
we identified the lines of code in the kernel that correspond to each of
one.

\item In order to test if a bug is triggerable, we created or located C
code to 
exploit each of the kernel bugs \cite{Exploit-Database}. We were able to
run and obtain results for 
35 out of the 69 bugs in our experiments. For the rest of the bugs, 
we could not find exploit code that would trigger them effectively at that
moment. 
In addition, it was very difficult to accurately determine if more complex
bugs 
were triggered or not. We leave further study and analysis of those bugs to
future work.

\item We compiled and ran the exploit C code under each virtualization
system to 
obtain their kernel traces, and then used our kernel trace safety metric to
determine 
if a specific bug was triggered inside that virtualization system. 

\item Lastly, to  analyze the reachable kernel paths for each of the
virtualization systems, 
we conducted system call fuzzing (similar to what we did in ?3) to obtain
the kernel trace in each system. 
We repeated the system call fuzzing within Repy as well to obtain its
kernel trace. 
\end{itemize}

\subsection{Comparison Results and Analysis}

Since our primary goal was to build a secure system, our core evaluation
was conducted primarily 
from a security perspective
(\S{\ref{Linux-Kernel-Bug-Test-and-Evaluation}}, 
\S{\ref{Reachable-Kernel-Trace-Analysis-for-Different-Virtualization-Systems}}, 
\S{\ref{Reachable-Kernel-Trace-Analysis-for-Repy-Sandbox}}). 
We also conducted an evaluation of the performance overhead of Lind
(\S{\ref{Performance-Evaluation}}) 
to obtain some understanding of its potential overall efficacy in
real-world settings.

\subsubsection{Linux Kernel Bug Test and Evaluation}
\label{Linux-Kernel-Bug-Test-and-Evaluation}

We tested 35 Linux kernel bugs in Native Linux, VirtualBox, VMWare
Workstation, Docker, Graphene, 
and Lind, to evaluate if any of them can be triggered. The kernel bugs
examined 
are capable of causing serious security problems. For example, 
the CVE-2014-8989 bug allows local users to bypass intended file
permissions by leveraging a POSIX ACL. 
When running applications, the potential risk of triggering some of these
kernel bugs here, 
and possibly many more bugs outside our list, is a severe problem that
users should be concerned about.

The results of verifying which kernel bugs were triggered under each
environment is illustrated in Table \ref{table:trigger_vulnerabilities}. 
We found that a substantial number of bugs were triggered in existing
virtualization systems. 
A full 35 out of 35 (100\%) bugs were triggered in Native Linux, 
while the other programs had somewhat lower rates: 14/35 (40\%) in
VirtualBox, 
11/35 (31.4\%)  in VMWare Workstation, 8/35 (22.9\%)  in Docker, and 8/35
(22.9\%) bugs in Graphene. 
In comparison, only 1 out of 35 bugs  (2.9\%)  was triggered in Lind. 
Comparing these results, Lind worked significantly better than the other
systems in limiting the triggering of kernel bugs.

\begin{table*}[!ht]
\scriptsize
\centering
\caption {Linux Kernel Bugs, and Vulnerabilities in Different
Virtualization Systems 
({\color{red}\ding{51}}: vulnerability triggered; \ding{55}: vulnerability
not triggered)}
\begin{tabular}{|l|c|c|c|c|c|c|}\hline
\textbf{Vulnerability}    &  \textbf{Native Linux}  &  \textbf{VirtualBox}
&  \textbf{VMWare Workstation}
 & \textbf{Docker} & \textbf{Graphene} & \textbf{Lind} \\
\hline
 CVE-2015-5706 & {\color{red}\ding{51}} & {\color{red}\ding{51}} &
{\color{red}\ding{51}} & {\color{red}\ding{51}} & {\color{red}\ding{51}} &
\ding{55}  \\
 CVE-2015-0239 & {\color{red}\ding{51}} & {\color{red}\ding{51}} &
{\color{red}\ding{51}} & \ding{55} & \ding{55}  & \ding{55}  \\
 CVE-2014-9584 & {\color{red}\ding{51}} & \ding{55}  & \ding{55}  &
\ding{55} & \ding{55}  & \ding{55}  \\
 CVE-2014-9529 & {\color{red}\ding{51}} & {\color{red}\ding{51}}  &
\ding{55}  & \ding{55} & \ding{55}  & \ding{55}  \\
 CVE-2014-9322 & {\color{red}\ding{51}} & {\color{red}\ding{51}}  &
\ding{55}  & {\color{red}\ding{51}} & {\color{red}\ding{51}}  & \ding{55}
\\
 CVE-2014-9090 & {\color{red}\ding{51}} & \ding{55}  & \ding{55}  &
\ding{55} & \ding{55}  & \ding{55}  \\
 CVE-2014-8989 & {\color{red}\ding{51}} & {\color{red}\ding{51}} &
{\color{red}\ding{51}} & {\color{red}\ding{51}} & {\color{red}\ding{51}} &
\ding{55}  \\
 CVE-2014-8559 & {\color{red}\ding{51}} & \ding{55}  & \ding{55}  &
\ding{55} & \ding{55}  & \ding{55}  \\
 CVE-2014-8369 & {\color{red}\ding{51}} & \ding{55}  & \ding{55}  &
\ding{55} & \ding{55}  & \ding{55}  \\
 CVE-2014-8160 & {\color{red}\ding{51}} & {\color{red}\ding{51}} &
{\color{red}\ding{51}} & \ding{55} & \ding{55}  & \ding{55}  \\
 CVE-2014-8134 & {\color{red}\ding{51}} & {\color{red}\ding{51}} &
{\color{red}\ding{51}} & \ding{55} & {\color{red}\ding{51}}  & \ding{55}
\\
 CVE-2014-8133 & {\color{red}\ding{51}} & {\color{red}\ding{51}}  &
\ding{55}  & \ding{55} & \ding{55}  & \ding{55}  \\
 CVE-2014-8086 & {\color{red}\ding{51}} & {\color{red}\ding{51}} &
{\color{red}\ding{51}} & {\color{red}\ding{51}} & \ding{55} & \ding{55}  \\
 CVE-2014-7975 & {\color{red}\ding{51}} & \ding{55}  & \ding{55}  &
\ding{55} & \ding{55}  & \ding{55}  \\
 CVE-2014-7970 & {\color{red}\ding{51}} & \ding{55}  & \ding{55}  &
\ding{55} & \ding{55}  & \ding{55}  \\
 CVE-2014-7842 & {\color{red}\ding{51}} & \ding{55}  & \ding{55}  &
\ding{55} & \ding{55}  & \ding{55}  \\
 CVE-2014-7826 & {\color{red}\ding{51}} & {\color{red}\ding{51}} &
{\color{red}\ding{51}} & \ding{55} & {\color{red}\ding{51}}  & \ding{55}
\\
 CVE-2014-7825 & {\color{red}\ding{51}} & {\color{red}\ding{51}} &
{\color{red}\ding{51}} & \ding{55} & {\color{red}\ding{51}}  & \ding{55}
\\
 CVE-2014-7283 & {\color{red}\ding{51}} & \ding{55}  & \ding{55}  &
\ding{55} & \ding{55}  & \ding{55}  \\
 CVE-2014-5207 & {\color{red}\ding{51}} & \ding{55}  & \ding{55}  &
\ding{55} & \ding{55}  & \ding{55}  \\
 CVE-2014-5206 & {\color{red}\ding{51}} & \ding{55}  &
{\color{red}\ding{51}}  & {\color{red}\ding{51}}& \ding{55}  & \ding{55}
\\
 CVE-2014-5045 & {\color{red}\ding{51}} & \ding{55}  & \ding{55}  &
\ding{55} & \ding{55}  & \ding{55}  \\
 CVE-2014-4943 & {\color{red}\ding{51}} & \ding{55}  & \ding{55}  &
\ding{55} & \ding{55}  & \ding{55}  \\
 CVE-2014-4667 & {\color{red}\ding{51}} & \ding{55}  & \ding{55}  &
\ding{55} & {\color{red}\ding{51}}  & \ding{55}  \\
 CVE-2014-4508 & {\color{red}\ding{51}} & \ding{55}  & \ding{55}  &
\ding{55} & \ding{55}  & \ding{55}  \\
 CVE-2014-4171 & {\color{red}\ding{51}} & {\color{red}\ding{51}} &
{\color{red}\ding{51}} & {\color{red}\ding{51}} & {\color{red}\ding{51}} &
{\color{red}\ding{51}}  \\
 CVE-2014-4157 & {\color{red}\ding{51}} & \ding{55}  & \ding{55}  &
\ding{55} & \ding{55}  & \ding{55}  \\
 CVE-2014-4014 & {\color{red}\ding{51}} & \ding{55}  &
{\color{red}\ding{51}}  & {\color{red}\ding{51}} & \ding{55}  & \ding{55}
\\
 CVE-2014-3940 & {\color{red}\ding{51}} & {\color{red}\ding{51}}  &
\ding{55}  & {\color{red}\ding{51}}& \ding{55}  & \ding{55}  \\
 CVE-2014-3917 & {\color{red}\ding{51}} & {\color{red}\ding{51}}  &
\ding{55}  & \ding{55} & \ding{55}  & \ding{55}  \\
 CVE-2014-3153 & {\color{red}\ding{51}} & \ding{55}  & \ding{55}  &
\ding{55} & \ding{55}  & \ding{55}  \\
 CVE-2014-3144 & {\color{red}\ding{51}} & \ding{55}  & \ding{55}  &
\ding{55} & \ding{55}  & \ding{55}  \\
 CVE-2014-3122 & {\color{red}\ding{51}} & \ding{55}  & \ding{55}  &
\ding{55} & \ding{55}  & \ding{55}  \\
 CVE-2014-2851 & {\color{red}\ding{51}} & \ding{55}  & \ding{55}  &
\ding{55} & \ding{55}  & \ding{55}  \\
 CVE-2014-0206 & {\color{red}\ding{51}} & \ding{55}  & \ding{55}  &
\ding{55} & \ding{55}  & \ding{55}  \\
\hline
\end{tabular}
\label{table:trigger_vulnerabilities}
\end{table*}

\subsubsection{Reachable Kernel Trace Analysis for Different Virtualization
Systems}
\label{Reachable-Kernel-Trace-Analysis-for-Different-Virtualization-Systems}

After establishing that Lind was efficient at finding bugs, our next step
was to examine how Lind was able to achieve this efficiency.  
To answer this question, we obtained the total reachable kernel trace for
each of the systems (including Lind) 
and did further analysis on the components of those traces. These results
are listed in Table \ref{table:trace-systems}.

As the numbers reveal, Lind accessed the minimum amount of code in the OS
kernel. More importantly, 
all the kernel code it accessed was in the safe portion of the kernel, the
commonly used kernel paths. 
As we have already verified in ?3.3\cappos{make link}, the safe portion of 
the kernel contains fewer kernel bugs. 
So it make sense that Lind is less likely to trigger kernel bugs. 

The other virtualization systems all accessed a substantial number of code
paths in the kernel, 
and they all had access to a larger section of the risky portion, the
uncommonly used kernel paths. 
Based on our hypothesis, many historical bugs, as well as undetected
zero-day bugs, could be located there. 
Thus, accessing the risky portion without restriction is dangerous, and
leads to kernel bug exploitation. 

To summarize, the secret of how Lind is able to trigger the least kernel
bugs lies in the important fact that 
it is better able to control access to the OS kernel. 
Thus, we would assert the better results achieved with Lind is a natural
outcome of its design.

\begin{table}
\centering
\scriptsize
\caption{Reachable Kernel Trace Analysis for Different Virtualization
Systems}
\begin{tabular}{|l|l|l|l|}
  \hline
  \multirow{3}{1.5cm}{\bf Virtualization system} & \multicolumn{3}{c|}{\bf Kernel trace} \\ \cline{2-4}
  & \multirow{2}{1.5cm}{Compared to native Linux} & \multirow{2}{1.8cm}{In safe portion 
  (common paths)} & \multirow{2}{2cm}{In risky portion (uncommon paths)} \\
  & & & \\  \hline
  VirtualBox & 78.8 \% & 46.5 \% & 53.5 \% \\
  \hline
  \multirow{2}{1.5cm}{VMWare Workstation} & \multirow{2}{*}{72.6 \%} & 
  \multirow{2}{*}{50.2 \%} & \multirow{2}{*}{49.8 \%} \\ 
  & & & \\   \hline
  Docker & 61.3 \% & 58.4 \% & 41.6 \% \\
  \hline
  Graphene & 49.2 \% & 65.1 \% & 34.9 \% \\
  \hline
  Lind & 36.2 \% & 100 \% & 0 \% \\
  \hline
\end{tabular}
\label{table:trace-systems}
\end{table}

\subsubsection{Reachable Kernel Trace Analysis for Repy Sandbox}
\label{Reachable-Kernel-Trace-Analysis-for-Repy-Sandbox}

An important question about Lind's security guarantee is what happens if
there is a bug or a failure in Lind's TCB, 
the Repy sandbox kernel. Because the TCB has direct access to the OS
kernel, if a bug occurs in the TCB, 
it can potentially access the privileged OS kernel and trigger kernel bugs. 

To determine if a flaw in the TCB could endanger a kernel, 
we obtained the total reachable kernel trace in Repy and analyzed its
components. 
The results are shown in Table \ref{table:trace-Repy}. The trace of Repy is
slightly larger (5.8\%) than that of Lind, 
which means that Repy's design can not allow attackers or bugs to 
have much access to the OS kernel. In fact, only a small amount (5.8\%) of
additional OS kernel paths might be open. 
More importantly, The kernel trace of Repy lies completely within the safe
portion of the OS kernel. 
Since the safe portion contains fewer kernel bugs, the Repy sandbox kernel
will have a very slim chance to trigger OS kernel bugs.

The design explained above shows that even if our Repy sandbox kernel has a
bug or failure inside, 
it only slightly increases the amount of OS kernel paths open to attacks,
and all these paths accessed are still inside the safe portion. 
Therefore, Repy will not grant attackers more opportunities to trigger OS
kernel bugs. 
Since Repy, arguably the main security weakness of the system, can be
considered safe by our analysis, 
it shows that Lind can provide strong security to run user applications.

\begin{table}
\centering
\scriptsize
\caption{Reachable Kernel Trace Analysis for the Repy Sandbox.  \cappos{Is
this correct?}}
\begin{tabular}{|l|l|l|l|l|}
  \hline
  \multirow{3}{.8cm}{\bf Sandbox} & \multicolumn{4}{c|}{\bf Kernel trace} \\ \cline{2-5}
  & \multirow{2}{1cm}{Compared to Lind} & 
  \multirow{2}{1.3cm}{Compared to native Linux} & \multirow{2}{1.7cm}{In safe portion 
  (common paths)} & \multirow{2}{1.9cm}{In risky portion (uncommon paths)} \\
  & & & & \\  \hline
  
%  Sandbox &  \thead{Kernel Trace \\ Compared to \\ Lind} & \thead{Kernel
%Trace \\ Compared to \\ Native Linux} &
%  \thead{Kernel Trace \\ in Safe Portion \\ (Common Paths)} & \thead{Kernel
%Trace \\ in Risky Portion \\ (Uncommon Paths)} \\
%  \hline
  Repy & 105.8 \% & 38.3 \% & 100 \%  & 0 \%  \\
  \hline
\end{tabular}
\label{table:trace-Repy}
\end{table}

\subsubsection{Performance Evaluation}
\label{Performance-Evaluation}

Since security systems still need to be efficient, economically and in
terms of performance, 
we also set up a test to demonstrate that Lind is a practical tool. 
We ran a variety of real-world applications in Lind and compared runtime
performance 
against that in Native Linux to measure the overhead cost it could incur.

We first compiled and ran three widely used applications, 
a primes calculator, GNU grep, and GNU wget. All ran unaltered and
correctly inside Lind. 
Figure \ref{fig:performance_applications} shows the runtime performance
results. 
The primes applications ran in Lind with 80\% of the performance of Native 
Linux.  \cappos{I'm confused.  How did you generate the results?}
We expect other CPU bound processes to behave similarly. 
Grep experienced roughly 10x slowdown over Native Linux, while the Wget
slowdown was roughly 20x. 

\begin{figure*}
\centering
\includegraphics[width=1.6\columnwidth]{diagram/lind_oakland16_performance.pdf}
\caption{Applications Runtime Performance: Native Linux vs. Lind \cappos{Is 
this right?}}
\label{fig:performance_applications}
\end{figure*}

Next, we ran the legacy application Tor in Lind. Tor runs unmodified in
Lind. 
\cappos{What about needing to compile it for NaCl?}
We used the benchmarks that come with Tor to test several of its common
operations. 
A summary of the results is shown in Table \ref{table:performance_tor}. The
benchmarks focus on cryptographic operations, 
which are CPU intensive, but also make syscalls like getpid, and reads to
/dev/urandom.
Cell processing executes full packet encryption and decryption. In our
test, 
Lind slowed these operations between 2.5x and 5x. We believe these
slowdowns 
are caused by the differences in the code produced by NaCl, and the
increased overhead from Lind system calls. 

As shown above,  Lind does incur some performance overhead in most cases. 
It should be noted though that, at this point, we have not  yet attempted
to optimize its performance. 
It might be argued that, since an attack on the kernel can have devastating
result, at this initial stage, 
a tradeoff between security and performance is justified. Despite this
issue, 
the fact that Lind is able to run many legacy applications suggests that it
is a positive step towards building new secure systems. 

\begin{table}
\centering
\scriptsize
\caption{Performance Results on Tor's Built-in Benchmark Program: Native
Linux vs. Lind.}
\begin{tabular}{|r|r|r|r|}
  \hline
  Benchmark & Native Code & Lind & Impact  \\
  \hline
  Digest Tests: & & & \\
  Set & 54.80 nsec/element & 176.86 nsec/element & 3.22x \\
  Get & 42.30 nsec/element & 134.38 nsec/element & 3.17x \\
  Add & 11.69 nsec/element & 53.91 nsec/element & 4.61x \\
  IsIn & 8.24 nsec/element & 39.82 nsec/element & 4.83x \\
  \hline
  AES Tests: & & & \\
  1 Byte & 14.83 nsec/B & 36.93 nsec/B & 2.49x \\
  16 Byte & 7.45 nsec/B & 16.95 nsec/B & 2.28x \\
  1024 Byte & 6.91 nsec/B & 15.42 nsec/B & 2.23x \\
  4096 Byte & 6.96 nsec/B & 15.35 nsec/B & 2.21x \\
  8192 Byte & 6.94 nsec/B & 15.47 nsec/B & 2.23x \\
  Cell Sized & 6.81 nsec/B & 14.71 nsec/B & 2.16x \\
  \hline
  Cell Processing: & & & \\
  Inbound & 3378.18 nsec/cell & 8418.03 nsec/cell & 2.49x \\
  (per Byte) & 6.64 nsec/B & 16.54 nsec/B & - \\
  Outbound & 3384.01 nsec/cell & 8127.42 nsec/cell & 2.40x \\
  (per Byte) & 6.65 nsec/B & 15.97 nsec/B & - \\
  \hline
\end{tabular}
\label{table:performance_tor}
\end{table}

